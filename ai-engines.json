{
  "version": "1.0.0",
  "last_updated": "2025-09-05",
  "engines": [
    {
      "id": "openai",
      "name": "OpenAI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": true,
        "image_editing": true,
        "embeddings": true,
        "speech_to_text": true,
        "text_to_speech": true,
        "code_execution": false,
        "web_search": true
      },
      "models": [
        {
          "model_id": "gpt-4.1",
          "name": "GPT-4.1",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "gpt-4.1-mini",
          "name": "GPT-4.1 Mini",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "gpt-4.1-nano",
          "name": "GPT-4.1 Nano",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "supports_vision": false,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "o3",
          "name": "o3",
          "type": "reasoning",
          "context_window": 200000,
          "max_output_tokens": 100000,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "knowledge_cutoff": "2024-12"
        },
        {
          "model_id": "o3-mini",
          "name": "o3-mini",
          "type": "reasoning",
          "context_window": 200000,
          "max_output_tokens": 100000,
          "supports_vision": false,
          "supports_function_calling": true,
          "reasoning_model": true,
          "reasoning_efforts": ["low", "medium", "high"],
          "knowledge_cutoff": "2024-12"
        },
        {
          "model_id": "gpt-4o",
          "name": "GPT-4o",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-10"
        },
        {
          "model_id": "gpt-4o-mini",
          "name": "GPT-4o Mini",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-10"
        },
        {
          "model_id": "gpt-3.5-turbo",
          "name": "GPT-3.5 Turbo",
          "type": "chat",
          "context_window": 16385,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true,
          "knowledge_cutoff": "2021-09"
        },
        {
          "model_id": "text-embedding-3-small",
          "name": "Text Embedding 3 Small",
          "type": "embedding",
          "dimensions": 1536
        },
        {
          "model_id": "text-embedding-3-large",
          "name": "Text Embedding 3 Large",
          "type": "embedding",
          "dimensions": 3072
        },
        {
          "model_id": "dall-e-3",
          "name": "DALL-E 3",
          "type": "image_generation",
          "supported_sizes": ["1024x1024", "1024x1792", "1792x1024"],
          "styles": ["natural", "vivid"],
          "default_size": "1024x1024"
        },
        {
          "model_id": "dall-e-2",
          "name": "DALL-E 2",
          "type": "image_generation",
          "supported_sizes": ["256x256", "512x512", "1024x1024"],
          "default_size": "1024x1024"
        }
      ],
      "endpoints": {
        "base_url": "https://api.openai.com/v1",
        "chat": "/chat/completions",
        "embeddings": "/embeddings",
        "images_generation": "/images/generations",
        "images_edit": "/images/edits",
        "audio_speech": "/audio/speech",
        "audio_transcriptions": "/audio/transcriptions",
        "models": "/models"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "anthropic",
      "name": "Anthropic",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "code_execution": true,
        "file_handling": true,
        "prompt_caching": true,
        "batch_processing": true,
        "extended_thinking": true,
        "interleaved_thinking": true,
        "tool_use": true
      },
      "models": [
        {
          "model_id": "claude-opus-4-1-20250805",
          "name": "Claude Opus 4.1",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "extended_thinking": true,
          "knowledge_cutoff": "2025-03"
        },
        {
          "model_id": "claude-opus-4-20250514",
          "name": "Claude Opus 4",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "extended_thinking": true,
          "knowledge_cutoff": "2025-03"
        },
        {
          "model_id": "claude-sonnet-4-20250514",
          "name": "Claude Sonnet 4",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 64000,
          "supports_vision": true,
          "supports_function_calling": true,
          "beta_context_window": 1000000,
          "beta_header_required": "context-1m-2025-08-07",
          "knowledge_cutoff": "2025-03"
        },
        {
          "model_id": "claude-3-7-sonnet-20250219",
          "name": "Claude Sonnet 3.7",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 64000,
          "supports_vision": true,
          "supports_function_calling": true,
          "extended_output_beta": 128000,
          "beta_header_required": "output-128k-2025-02-19",
          "knowledge_cutoff": "2024-11"
        },
        {
          "model_id": "claude-3-5-haiku-20241022",
          "name": "Claude 3.5 Haiku",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-07"
        },
        {
          "model_id": "claude-3-haiku-20240307",
          "name": "Claude 3 Haiku",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 4096,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2023-08"
        }
      ],
      "endpoints": {
        "base_url": "https://api.anthropic.com",
        "messages": "/v1/messages"
      },
      "headers_required": {
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
      },
      "authentication": {
        "type": "header",
        "header": "x-api-key"
      }
    },
    {
      "id": "google",
      "name": "Google AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": true,
        "image_editing": true,
        "embeddings": true,
        "speech_to_text": true,
        "text_to_speech": true,
        "video_generation": true,
        "thinking": true,
        "live_api": true,
        "native_tool_use": true
      },
      "models": [
        {
          "model_id": "gemini-2.5-pro",
          "name": "Gemini 2.5 Pro",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 65536,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true,
          "thinking": true,
          "supports_audio": true,
          "supports_video": true,
          "supports_pdf": true
        },
        {
          "model_id": "gemini-2.5-flash",
          "name": "Gemini 2.5 Flash",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 65536,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true,
          "thinking": true,
          "supports_audio": true,
          "supports_video": true,
          "live_api": true
        },
        {
          "model_id": "gemini-2.5-flash-lite",
          "name": "Gemini 2.5 Flash-Lite",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 65536,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true,
          "cost_efficient": true
        },
        {
          "model_id": "gemini-2.0-flash",
          "name": "Gemini 2.0 Flash",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 32768,
          "supports_vision": true,
          "supports_function_calling": true,
          "native_tool_use": true,
          "multimodal": true,
          "image_generation": true
        },
        {
          "model_id": "gemini-embedding-001",
          "name": "Gemini Embedding 001",
          "type": "embedding",
          "dimensions": 3072
        }
      ],
      "endpoints": {
        "base_url": "https://generativelanguage.googleapis.com/v1beta",
        "models": "/models",
        "generate_content": "/models/{model}:generateContent",
        "embed_content": "/models/{model}:embedContent"
      },
      "alternative_endpoints": {
        "vertex_ai": {
          "base_pattern": "https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/publishers/google/models/{MODEL_ID}:predict"
        }
      },
      "authentication": {
        "type": "query",
        "parameter": "key"
      }
    },
    {
      "id": "mistral",
      "name": "Mistral AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false,
        "document_understanding": true,
        "ocr": true,
        "code_generation": true,
        "multimodal": true,
        "software_engineering": true
      },
      "models": [
        {
          "model_id": "mistral-medium-2508",
          "name": "Mistral Medium 3.1",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "mistral-large-2411",
          "name": "Mistral Large (24.11)",
          "type": "chat",
          "context_window": 131072,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "123B"
        },
        {
          "model_id": "pixtral-large-2411",
          "name": "Pixtral Large (24.11)",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true,
          "parameters": "124B",
          "vision_encoder": "1B",
          "min_images": 30
        },
        {
          "model_id": "mistral-small-2506",
          "name": "Mistral Small 3.2",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "license": "Apache2"
        },
        {
          "model_id": "open-mistral-nemo",
          "name": "Mistral Nemo 12B",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "multilingual": true,
          "parameters": "12B"
        },
        {
          "model_id": "ministral-8b-2410",
          "name": "Ministral 8B",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "edge_optimized": true,
          "parameters": "8B"
        },
        {
          "model_id": "devstral-small-2505",
          "name": "Devstral Small 2505",
          "type": "code",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "24B",
          "software_engineering": true,
          "swe_bench_score": 46.8
        },
        {
          "model_id": "mistral-ocr-2503",
          "name": "Mistral OCR (25.03)",
          "type": "ocr",
          "max_pages": 1000,
          "max_file_size": "50MB",
          "supports_vision": true,
          "supports_function_calling": false,
          "processing_speed": "2000_pages_per_minute"
        },
        {
          "model_id": "codestral-2508",
          "name": "Codestral 2508",
          "type": "code",
          "context_window": 256000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "programming_languages": "80+",
          "parameters": "22B"
        },
        {
          "model_id": "mistral-embed",
          "name": "Mistral Embed",
          "type": "embedding",
          "dimensions": 1024
        }
      ],
      "endpoints": {
        "base_url": "https://api.mistral.ai/v1",
        "chat": "/chat/completions",
        "embeddings": "/embeddings"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "groq",
      "name": "Groq",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "batch_processing": true,
        "vision": true,
        "multimodal": true,
        "fast_inference": true,
        "tool_use": true
      },
      "models": [
        {
          "model_id": "gpt-oss-120b",
          "name": "GPT-OSS 120B",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "120B_total_5.1B_active",
          "architecture": "MoE",
          "experts": 128
        },
        {
          "model_id": "llama-3.3-70b-versatile",
          "name": "Llama 3.3 70B Versatile",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "70B",
          "multilingual": true
        },
        {
          "model_id": "llama-3.1-8b-instant",
          "name": "Llama 3.1 8B Instant",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "8B",
          "instant_responses": true,
          "speed_tokens_per_second": 1200
        },
        {
          "model_id": "moonshotai/kimi-k2-instruct",
          "name": "Kimi K2 Instruct (1T MoE)",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 32000,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "1T_total_32B_active",
          "experts": 384,
          "agentic": true
        },
        {
          "model_id": "meta-llama/llama-4-scout-17b-16e-instruct",
          "name": "Llama 4 Scout Vision",
          "type": "chat",
          "context_window": 10000000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true,
          "parameters": "17B_active_109B_total",
          "experts": 16,
          "speed_tokens_per_second": 460
        },
        {
          "model_id": "meta-llama/llama-4-maverick-17b-128e-instruct",
          "name": "Llama 4 Maverick Vision",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true,
          "parameters": "17B_active_400B_total",
          "experts": 128,
          "multilingual": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.groq.com/openai/v1",
        "chat": "/chat/completions",
        "models": "/models",
        "batch": "/batch"
      },
      "service_tiers": ["on_demand", "flex", "auto"],
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "xai",
      "name": "xAI (Grok)",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": true,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "tool_use": true,
        "live_search": true,
        "structured_outputs": true,
        "code_execution": true,
        "cached_prompts": true
      },
      "models": [
        {
          "model_id": "grok-4",
          "name": "Grok 4",
          "type": "chat",
          "context_window": 130000,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "multimodal": true,
          "knowledge_cutoff": "2024-11"
        },
        {
          "model_id": "grok-code-fast-1",
          "name": "Grok Code Fast 1",
          "type": "code",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true,
          "reasoning_model": true
        },
        {
          "model_id": "grok-3",
          "name": "Grok 3",
          "type": "chat",
          "context_window": 130000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-11"
        },
        {
          "model_id": "grok-2",
          "name": "Grok 2 (Deprecated)",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true,
          "deprecated": true,
          "deprecation_date": "2025-09-15",
          "migration_target": "grok-4"
        }
      ],
      "endpoints": {
        "base_url": "https://api.x.ai/v1",
        "chat": "/chat/completions",
        "models": "/models"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "notes": {
        "openai_compatible": true,
        "live_search_pricing": "$0.025 per source"
      }
    },
    {
      "id": "perplexity",
      "name": "Perplexity AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "real_time_search": true,
        "citations": true,
        "search_filters": true
      },
      "models": [
        {
          "model_id": "sonar",
          "name": "Sonar",
          "type": "search",
          "context_window": 127000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "factuality_score": 0.773
        },
        {
          "model_id": "sonar-pro",
          "name": "Sonar Pro",
          "type": "search",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "factuality_score": 0.858,
          "enhanced_citations": true
        },
        {
          "model_id": "sonar-reasoning",
          "name": "Sonar Reasoning",
          "type": "reasoning",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "reasoning_model": true
        },
        {
          "model_id": "sonar-reasoning-pro",
          "name": "Sonar Reasoning Pro",
          "type": "reasoning",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "reasoning_model": true,
          "powered_by": "DeepSeek-R1"
        },
        {
          "model_id": "sonar-deep-research",
          "name": "Sonar Deep Research",
          "type": "research",
          "context_window": 200000,
          "max_output_tokens": 16384,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "comprehensive_reports": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.perplexity.ai",
        "chat": "/chat/completions"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "pricing": {
        "sonar": {
          "search": "$5 per 1000 searches",
          "input": "$1 per 750K words",
          "output": "$1 per 750K words"
        },
        "sonar_pro": {
          "search": "$5 per 1000 searches",
          "input": "$3 per 750K words",
          "output": "$15 per 750K words"
        }
      },
      "notes": {
        "openai_compatible": true,
        "pro_credits": "$5 monthly for pro subscribers"
      }
    },
    {
      "id": "cohere",
      "name": "Cohere",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false,
        "rag_optimized": true
      },
      "models": [
        {
          "model_id": "command-r",
          "name": "Command R",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "command-r-plus",
          "name": "Command R+",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "embed-3.5",
          "name": "Cohere Embed 3.5",
          "type": "embedding",
          "dimensions": 1024,
          "multilingual": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.cohere.ai/v1",
        "chat": "/chat",
        "embeddings": "/embed"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "deepseek",
      "name": "DeepSeek",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false
      },
      "models": [
        {
          "model_id": "deepseek-v3",
          "name": "DeepSeek V3",
          "type": "chat",
          "context_window": 64000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "671B"
        }
      ],
      "endpoints": {
        "base_url": "https://api.deepseek.com/v1",
        "chat": "/chat/completions"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "pricing": {
        "input": "$0.27 per 1M tokens",
        "output": "$1.10 per 1M tokens"
      }
    },
    {
      "id": "together",
      "name": "Together AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false,
        "fine_tuning": true
      },
      "models": [
        {
          "model_id": "together-embeddings",
          "name": "Together Embeddings",
          "type": "embedding",
          "dimensions": 1024
        }
      ],
      "endpoints": {
        "base_url": "https://api.together.xyz/v1",
        "chat": "/chat/completions",
        "embeddings": "/embeddings"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "pricing": {
        "embeddings": "$0.008 per 1M tokens"
      }
    },
    {
      "id": "fireworks",
      "name": "Fireworks AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "fast_inference": true
      },
      "models": [
        {
          "model_id": "llama-3.2-70b",
          "name": "Llama 3.2 70B",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "mixtral-8x7b",
          "name": "Mixtral 8x7B",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.fireworks.ai/inference/v1",
        "chat": "/chat/completions"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    }
  ],
  "metadata": {
    "description": "AI Engines configuration for WordPress plugins",
    "documentation": "https://github.com/yourusername/AIEngines/blob/main/README.md",
    "schema_version": "1.0.0"
  }
}