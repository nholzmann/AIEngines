{
  "version": "1.0.0",
  "last_updated": "2025-09-04",
  "engines": [
    {
      "id": "openai",
      "name": "OpenAI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": true,
        "image_editing": true,
        "embeddings": true,
        "speech_to_text": true,
        "text_to_speech": true,
        "code_execution": false,
        "web_search": true
      },
      "models": [
        {
          "model_id": "gpt-5",
          "name": "GPT-5",
          "type": "reasoning",
          "context_window": 400000,
          "max_output_tokens": 128000,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "multimodal": true,
          "knowledge_cutoff": "2024-10"
        },
        {
          "model_id": "gpt-5-mini",
          "name": "GPT-5 Mini",
          "type": "reasoning",
          "context_window": 400000,
          "max_output_tokens": 128000,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "knowledge_cutoff": "2024-10"
        },
        {
          "model_id": "gpt-5-nano",
          "name": "GPT-5 Nano",
          "type": "reasoning",
          "context_window": 400000,
          "max_output_tokens": 128000,
          "supports_vision": false,
          "supports_function_calling": true,
          "reasoning_model": true,
          "knowledge_cutoff": "2024-10"
        },
        {
          "model_id": "gpt-4.1",
          "name": "GPT-4.1",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "gpt-4.1-mini",
          "name": "GPT-4.1 Mini",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 32000,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "gpt-4.1-nano",
          "name": "GPT-4.1 Nano",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "supports_vision": false,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "o3",
          "name": "o3",
          "type": "reasoning",
          "context_window": 200000,
          "max_output_tokens": 100000,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "knowledge_cutoff": "2024-06"
        },
        {
          "model_id": "o3-mini",
          "name": "o3-mini",
          "type": "reasoning",
          "context_window": 200000,
          "max_output_tokens": 100000,
          "supports_vision": false,
          "supports_function_calling": true,
          "reasoning_model": true,
          "knowledge_cutoff": "2023-10"
        },
        {
          "model_id": "gpt-4o",
          "name": "GPT-4o",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "supports_vision": true,
          "supports_function_calling": true
        },
        {
          "model_id": "gpt-4o-mini",
          "name": "GPT-4o Mini",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 16384,
          "supports_vision": true,
          "supports_function_calling": true
        },
        {
          "model_id": "gpt-3.5-turbo",
          "name": "GPT-3.5 Turbo",
          "type": "chat",
          "context_window": 16385,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "text-embedding-3-small",
          "name": "Text Embedding 3 Small",
          "type": "embedding",
          "dimensions": 1536
        },
        {
          "model_id": "text-embedding-3-large",
          "name": "Text Embedding 3 Large",
          "type": "embedding",
          "dimensions": 3072
        },
        {
          "model_id": "dall-e-3",
          "name": "DALL-E 3",
          "type": "image_generation",
          "supported_sizes": ["1024x1024", "1024x1792", "1792x1024"],
          "styles": ["natural", "vivid"],
          "default_size": "1024x1024"
        },
        {
          "model_id": "dall-e-2",
          "name": "DALL-E 2",
          "type": "image_generation",
          "supported_sizes": ["256x256", "512x512", "1024x1024"],
          "default_size": "1024x1024"
        }
      ],
      "endpoints": {
        "base_url": "https://api.openai.com/v1",
        "chat": "/chat/completions",
        "embeddings": "/embeddings",
        "images_generation": "/images/generations",
        "images_edit": "/images/edits",
        "audio_speech": "/audio/speech",
        "audio_transcriptions": "/audio/transcriptions",
        "models": "/models"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "anthropic",
      "name": "Anthropic",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "code_execution": true,
        "file_handling": true,
        "prompt_caching": true,
        "batch_processing": true
      },
      "models": [
        {
          "model_id": "claude-opus-4.1",
          "name": "Claude Opus 4.1",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "knowledge_cutoff": "2024-04"
        },
        {
          "model_id": "claude-sonnet-4",
          "name": "Claude Sonnet 4",
          "type": "chat",
          "context_window": 1000000,
          "max_output_tokens": 64000,
          "supports_vision": true,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-04"
        },
        {
          "model_id": "claude-sonnet-3.7-20250514",
          "name": "Claude Sonnet 3.7",
          "type": "chat",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.anthropic.com",
        "messages": "/v1/messages"
      },
      "headers_required": {
        "anthropic-version": "2023-06-01",
        "content-type": "application/json"
      },
      "authentication": {
        "type": "header",
        "header": "x-api-key"
      }
    },
    {
      "id": "google",
      "name": "Google AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false
      },
      "models": [
        {
          "model_id": "gemini-2.5-pro",
          "name": "Gemini 2.5 Pro",
          "type": "chat",
          "context_window": 2097152,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "gemini-2.5-flash",
          "name": "Gemini 2.5 Flash",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "gemini-2.0-flash",
          "name": "Gemini 2.0 Flash",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "tool_use": true
        },
        {
          "model_id": "gemini-1.5-pro",
          "name": "Gemini 1.5 Pro",
          "type": "chat",
          "context_window": 2097152,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true
        },
        {
          "model_id": "gemini-1.5-flash",
          "name": "Gemini 1.5 Flash",
          "type": "chat",
          "context_window": 1048576,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true
        },
        {
          "model_id": "gemini-embedding-001",
          "name": "Gemini Embedding 001",
          "type": "embedding",
          "dimensions": 3072
        }
      ],
      "endpoints": {
        "base_url": "https://generativelanguage.googleapis.com/v1beta",
        "models": "/models",
        "generate_content": "/models/{model}:generateContent",
        "embed_content": "/models/{model}:embedContent"
      },
      "alternative_endpoints": {
        "vertex_ai": {
          "base_pattern": "https://{REGION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{REGION}/publishers/google/models/{MODEL_ID}:predict"
        }
      },
      "authentication": {
        "type": "query",
        "parameter": "key"
      }
    },
    {
      "id": "mistral",
      "name": "Mistral AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false,
        "document_understanding": true
      },
      "models": [
        {
          "model_id": "mistral-medium-3",
          "name": "Mistral Medium 3",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "mistral-large-2411",
          "name": "Mistral Large (24.11)",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "mistral-small-3.1-2503",
          "name": "Mistral Small 3.1 (25.03)",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "devstral-small",
          "name": "Devstral Small",
          "type": "code",
          "context_window": 32000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "mistral-saba-2405",
          "name": "Mistral Saba (24B)",
          "type": "chat",
          "context_window": 32000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "mistral-ocr-2505",
          "name": "Mistral OCR (25.05)",
          "type": "ocr",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": true,
          "supports_function_calling": false
        },
        {
          "model_id": "codestral-2501",
          "name": "Codestral (25.01)",
          "type": "code",
          "context_window": 32000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "mistral-embed",
          "name": "Mistral Embed",
          "type": "embedding",
          "dimensions": 1024
        }
      ],
      "endpoints": {
        "base_url": "https://api.mistral.ai/v1",
        "chat": "/chat/completions",
        "embeddings": "/embeddings"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "groq",
      "name": "Groq",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "batch_processing": true
      },
      "models": [
        {
          "model_id": "gpt-oss-120b",
          "name": "GPT-OSS 120B",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "llama-3.3-70b-versatile",
          "name": "Llama 3.3 70B Versatile",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "llama3-8b-8192",
          "name": "Llama 3 8B",
          "type": "chat",
          "context_window": 8192,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "llama-3.1-8b-instant",
          "name": "Llama 3.1 8B Instant",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "kimi-k2-instruct",
          "name": "Kimi K2 Instruct (1T MoE)",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "llama-4-scout-17b-16e-instruct",
          "name": "Llama 4 Scout Vision",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "llama-4-maverick-17b-128e-instruct",
          "name": "Llama 4 Maverick Vision",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "multimodal": true
        },
        {
          "model_id": "mixtral-8x7b-32768",
          "name": "Mixtral 8x7B",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.groq.com/openai/v1",
        "chat": "/chat/completions",
        "models": "/models",
        "batch": "/batch"
      },
      "service_tiers": ["on_demand", "flex", "auto"],
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "xai",
      "name": "xAI (Grok)",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": true,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "tool_use": true,
        "live_search": true,
        "structured_outputs": true,
        "code_execution": true,
        "cached_prompts": true
      },
      "models": [
        {
          "model_id": "grok-4",
          "name": "Grok 4",
          "type": "chat",
          "context_window": 130000,
          "max_output_tokens": 8192,
          "supports_vision": true,
          "supports_function_calling": true,
          "reasoning_model": true,
          "multimodal": true,
          "knowledge_cutoff": "2024-11"
        },
        {
          "model_id": "grok-code-fast-1",
          "name": "Grok Code Fast 1",
          "type": "code",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true,
          "reasoning_model": true
        },
        {
          "model_id": "grok-3",
          "name": "Grok 3",
          "type": "chat",
          "context_window": 130000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true,
          "knowledge_cutoff": "2024-11"
        },
        {
          "model_id": "grok-2",
          "name": "Grok 2 (Deprecated)",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true,
          "deprecated": true,
          "deprecation_date": "2025-09-15",
          "migration_target": "grok-4"
        }
      ],
      "endpoints": {
        "base_url": "https://api.grok.xai.com/v1",
        "chat": "/chat/completions",
        "models": "/models"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "notes": {
        "openai_compatible": true,
        "live_search_pricing": "$0.025 per source"
      }
    },
    {
      "id": "perplexity",
      "name": "Perplexity AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "real_time_search": true,
        "citations": true,
        "search_filters": true
      },
      "models": [
        {
          "model_id": "sonar",
          "name": "Sonar",
          "type": "search",
          "context_window": 127000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "factuality_score": 0.773
        },
        {
          "model_id": "sonar pro",
          "name": "Sonar Pro",
          "type": "search",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "factuality_score": 0.858,
          "enhanced_citations": true
        },
        {
          "model_id": "sonar reasoning",
          "name": "Sonar Reasoning",
          "type": "reasoning",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "reasoning_model": true
        },
        {
          "model_id": "sonar reasoning pro",
          "name": "Sonar Reasoning Pro",
          "type": "reasoning",
          "context_window": 200000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "reasoning_model": true,
          "powered_by": "DeepSeek-R1"
        },
        {
          "model_id": "sonar deep research",
          "name": "Sonar Deep Research",
          "type": "research",
          "context_window": 200000,
          "max_output_tokens": 16384,
          "supports_vision": false,
          "supports_function_calling": false,
          "search_enabled": true,
          "comprehensive_reports": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.perplexity.ai",
        "chat": "/chat/completions"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "pricing": {
        "sonar": {
          "search": "$5 per 1000 searches",
          "input": "$1 per 750K words",
          "output": "$1 per 750K words"
        },
        "sonar_pro": {
          "search": "$5 per 1000 searches",
          "input": "$3 per 750K words",
          "output": "$15 per 750K words"
        }
      },
      "notes": {
        "openai_compatible": true,
        "pro_credits": "$5 monthly for pro subscribers"
      }
    },
    {
      "id": "cohere",
      "name": "Cohere",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false,
        "rag_optimized": true
      },
      "models": [
        {
          "model_id": "command-r",
          "name": "Command R",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "command-r-plus",
          "name": "Command R+",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "embed-3.5",
          "name": "Cohere Embed 3.5",
          "type": "embedding",
          "dimensions": 1024,
          "multilingual": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.cohere.ai/v1",
        "chat": "/chat",
        "embeddings": "/embed"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    },
    {
      "id": "deepseek",
      "name": "DeepSeek",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false
      },
      "models": [
        {
          "model_id": "deepseek-v3",
          "name": "DeepSeek V3",
          "type": "chat",
          "context_window": 64000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true,
          "parameters": "671B"
        }
      ],
      "endpoints": {
        "base_url": "https://api.deepseek.com/v1",
        "chat": "/chat/completions"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "pricing": {
        "input": "$0.27 per 1M tokens",
        "output": "$1.10 per 1M tokens"
      }
    },
    {
      "id": "together",
      "name": "Together AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": true,
        "speech_to_text": false,
        "text_to_speech": false,
        "fine_tuning": true
      },
      "models": [
        {
          "model_id": "together-embeddings",
          "name": "Together Embeddings",
          "type": "embedding",
          "dimensions": 1024
        }
      ],
      "endpoints": {
        "base_url": "https://api.together.xyz/v1",
        "chat": "/chat/completions",
        "embeddings": "/embeddings"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      },
      "pricing": {
        "embeddings": "$0.008 per 1M tokens"
      }
    },
    {
      "id": "fireworks",
      "name": "Fireworks AI",
      "status": "active",
      "capabilities": {
        "text_generation": true,
        "image_generation": false,
        "image_editing": false,
        "embeddings": false,
        "speech_to_text": false,
        "text_to_speech": false,
        "fast_inference": true
      },
      "models": [
        {
          "model_id": "llama-3.2-70b",
          "name": "Llama 3.2 70B",
          "type": "chat",
          "context_window": 128000,
          "max_output_tokens": 8192,
          "supports_vision": false,
          "supports_function_calling": true
        },
        {
          "model_id": "mixtral-8x7b",
          "name": "Mixtral 8x7B",
          "type": "chat",
          "context_window": 32768,
          "max_output_tokens": 4096,
          "supports_vision": false,
          "supports_function_calling": true
        }
      ],
      "endpoints": {
        "base_url": "https://api.fireworks.ai/inference/v1",
        "chat": "/chat/completions"
      },
      "authentication": {
        "type": "bearer",
        "header": "Authorization",
        "prefix": "Bearer"
      }
    }
  ],
  "metadata": {
    "description": "AI Engines configuration for WordPress plugins",
    "documentation": "https://github.com/yourusername/AIEngines/blob/main/README.md",
    "schema_version": "1.0.0"
  }
}